{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Let me listen to the music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Content <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Stage 1. Data Description](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [Stage 2. Data Preprocessing](#data_preprocessing)\n",
    "    * [2.1 Header Style](#header_style)\n",
    "    * [2.2 Missing Values](#missing_values)\n",
    "    * [2.3 Duplicates](#duplicates)\n",
    "    * [2.4 Conclusions](#data_preprocessing_conclusions)\n",
    "* [Stage 3. Hypothesis Testing](#hypothesis)\n",
    "    * [3.1 Hypothesis 1: User Activity in Two Cities](#activity)\n",
    "* [Conclusions](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introduction <a id='intro'></a>\n",
    "As a data analyst, your job is to analyze data to extract valuable information and make decisions based on it. This involves different stages, such as data description, preprocessing, and hypothesis testing.\n",
    "\n",
    "Whenever we investigate, we need to formulate hypotheses that we can later test. Sometimes we accept these hypotheses; other times, we reject them. To make the right decisions, a company must be able to understand whether it is making the right assumptions.\n",
    "\n",
    "In this project, you will compare the musical preferences of the cities of Springfield and Shelbyville. You will study real online music streaming data to test the hypothesis below and compare the behavior of users in these two cities.\n",
    "\n",
    "### Objective:\n",
    "Test the hypothesis:\n",
    "1. User activity differs by day of the week and city.\n",
    "\n",
    "### Stages\n",
    "The user behavior data is stored in the file `/datasets/music_project_en.csv`. There is no information about the data quality, so you will need to examine it before testing the hypothesis.\n",
    "\n",
    "First, you will assess the data quality and see if the issues are significant. Then, during data preprocessing, you will address the most critical problems.\n",
    "\n",
    "Your project will consist of three stages:\n",
    " 1. Data Description.\n",
    " 2. Data Preprocessing.\n",
    " 3. Hypothesis Testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Stage 1. Data Description <a id='data_review'></a>\n",
    "\n",
    "Open the data and examine it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57eAOGIz_Zcs"
   },
   "source": [
    "You will need `pandas`, so import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AXN7PHPN_Zcs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Read the file `music_project_en.csv` and store it in the variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fFVu7vqh_Zct"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv ('/datasets/music_project_en.csv') # Read the file and store it in df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoOMd3uTqnZ"
   },
   "source": [
    "Display the first 10 rows of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oWTVX3gW_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>Track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFB692EC</td>\n",
       "      <td>Kamigata To Boots</td>\n",
       "      <td>The Mass Missile</td>\n",
       "      <td>rock</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:28:33</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55204538</td>\n",
       "      <td>Delayed Because of Accident</td>\n",
       "      <td>Andreas Rönnberg</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>14:07:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20EC38</td>\n",
       "      <td>Funiculì funiculà</td>\n",
       "      <td>Mario Lanza</td>\n",
       "      <td>pop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:58:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DD03C9</td>\n",
       "      <td>Dragons in the Sunset</td>\n",
       "      <td>Fire + Ice</td>\n",
       "      <td>folk</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>08:37:09</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2DC1FAE</td>\n",
       "      <td>Soul People</td>\n",
       "      <td>Space Echo</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>08:34:34</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>842029A1</td>\n",
       "      <td>Chains</td>\n",
       "      <td>Obladaet</td>\n",
       "      <td>rusrap</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>13:09:41</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4CB90AA5</td>\n",
       "      <td>True</td>\n",
       "      <td>Roman Messer</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>13:00:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F03E1C1F</td>\n",
       "      <td>Feeling This Way</td>\n",
       "      <td>Polina Griffith</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>20:47:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8FA1D3BE</td>\n",
       "      <td>L’estate</td>\n",
       "      <td>Julia Dalia</td>\n",
       "      <td>ruspop</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>09:17:40</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E772D5C0</td>\n",
       "      <td>Pessimist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dance</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>21:20:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID                        Track            artist   genre  \\\n",
       "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
       "1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n",
       "2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n",
       "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
       "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
       "5  842029A1                       Chains          Obladaet  rusrap   \n",
       "6  4CB90AA5                         True      Roman Messer   dance   \n",
       "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
       "8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n",
       "9  E772D5C0                    Pessimist               NaN   dance   \n",
       "\n",
       "        City        time        Day  \n",
       "0  Shelbyville  20:28:33  Wednesday  \n",
       "1  Springfield  14:07:09     Friday  \n",
       "2  Shelbyville  20:58:07  Wednesday  \n",
       "3  Shelbyville  08:37:09     Monday  \n",
       "4  Springfield  08:34:34     Monday  \n",
       "5  Shelbyville  13:09:41     Friday  \n",
       "6  Springfield  13:00:07  Wednesday  \n",
       "7  Springfield  20:47:49  Wednesday  \n",
       "8  Springfield  09:17:40     Friday  \n",
       "9  Shelbyville  21:20:49  Wednesday  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10) # Get the first 10 rows of the df table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO73Kwic_Zct"
   },
   "source": [
    "Get the general information about the table with a command. You know the method that shows the general information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DSf2kIb-_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (df.info()) # Get the general information about our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "These are our observations about the table. It contains seven columns. They store the same data types: `object`.\n",
    "\n",
    "According to the documentation:\n",
    "- `'userID'`: user ID;\n",
    "- `'Track'`: song title;\n",
    "- `'artist'`: artist name;\n",
    "- `'genre'`: track genre;\n",
    "- `'City'`: city of the user;\n",
    "- `'time'`: exact time the song was played;\n",
    "- `'Day'`: day of the week.\n",
    "\n",
    "We can see three issues with the header style in the table:\n",
    "1. Some headers are in uppercase, others are in lowercase.\n",
    "2. There are spaces in some headers.\n",
    "3. In the `'userID'` header, word union is not used correctly, and there is an unnecessary capital letter. `Detect the third issue on your own and describe it here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "### Write your own observations. These are some questions that may be helpful: <a id='data_review_conclusions'></a>\n",
    "\n",
    "1.  `What type of data do we have in the rows? And how can we understand what the columns store?`  \n",
    "    A/ The data is of string type, determined by dtype.\n",
    "\n",
    "2.  `Is there enough data to provide answers to our hypothesis, or do we need more information?`  \n",
    "    A/ The information provided is sufficient for some calculations; however, expanding it would be much better.\n",
    "\n",
    "3.  `Did you notice any issues with the data, such as missing values, duplicates, or incorrect data types?`  \n",
    "    A/ Yes, there are missing values in 'Track' (1343), 'artist' (7567), and 'genre' (1198). There are also duplicate values, totaling 3826."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eL__vcwViOi"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Stage 2. Data Preprocessing <a id='data_preprocessing'></a>\n",
    "\n",
    "The goal here is to prepare the data for analysis.\n",
    "The first step is to resolve any issues with the headers. Then, we can move on to missing and duplicate values. Let's begin.\n",
    "\n",
    "Fix the format of the table headers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Header Style <a id='header_style'></a>\n",
    "Display the headers of the table (column names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oKOTdF_Q_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)# Display the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Change the table headers according to good style rules:\n",
    "* All characters must be lowercase.\n",
    "* Remove the spaces.\n",
    "* If the name has multiple words, use snake_case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu0zkfe5zNJe"
   },
   "source": [
    "Previously, you learned about the automatic way of renaming columns. Let's apply it now. Use a for loop to iterate over the column names and make all characters lowercase. When you're done, display the table headers again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6I_RwwMhzM4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  userid', 'track', 'artist', 'genre', '  city  ', 'time', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Loop through the headers and make everything lowercase\n",
    "\n",
    "new_col_columns = []\n",
    "\n",
    "for old_name in df.columns :\n",
    "    name_lowered = old_name.lower ()\n",
    "    new_col_columns.append (name_lowered)\n",
    "    \n",
    "df.columns = new_col_columns\n",
    "\n",
    "print (new_col_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pweIRxjSzPYW"
   },
   "source": [
    "Now, using the same method, remove the spaces at the beginning and end of the column names, and print the column names again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vVQXbFyJzSYl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userid', 'track', 'artist', 'genre', 'city', 'time', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Loop through the headers and remove the spaces\n",
    "\n",
    "new_col_columns = []\n",
    "\n",
    "for old_name in df.columns :\n",
    "    name_stripped = old_name.strip ()\n",
    "    new_col_columns.append (name_stripped)\n",
    "    \n",
    "df.columns = new_col_columns\n",
    "    \n",
    "print (new_col_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCb8MW1JzURd"
   },
   "source": [
    "We need to apply the snake_case rule to the `userid` column. It should be `user_id`. Change the name of this column and display the names of all columns when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ISlFqs5y_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Change the name of the \"userid\" column\n",
    "\n",
    "new_col_names = []\n",
    "\n",
    "for old_name in df.columns :\n",
    "    name_no_spaces = old_name.replace ('userid','user_id')\n",
    "    new_col_names.append (name_no_spaces)\n",
    "    \n",
    "df.columns = new_col_names\n",
    "\n",
    "print (new_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Check the result. Display the headers once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d4NOAmTW_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day']\n"
     ]
    }
   ],
   "source": [
    "# Check the result: the list of headers\n",
    "print (new_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Missing Values <a id='missing_values'></a>\n",
    "First, find the number of missing values in the table. You should use two methods in sequence to get the number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RskX29qr_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id       0\n",
      "track      1343\n",
      "artist     7567\n",
      "genre      1198\n",
      "city          0\n",
      "time          0\n",
      "day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of missing values\n",
    "print (df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "Not all missing values affect the research. For example, missing values in `track` and `artist` are not crucial. You can simply replace them with default values like the string `'unknown'`.\n",
    "\n",
    "However, missing values in `'genre'` can affect the comparison between the musical preferences of Springfield and Shelbyville. In real life, it would be useful to know the reasons why there is missing data and try to recover it. But we don't have that opportunity in this project. So, you will need to:\n",
    "* fill these missing values with a default value;\n",
    "* evaluate how much the missing values could affect your computations;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Replace the missing values in the columns `'track'`, `'artist'`, and `'genre'` with the string `'unknown'`. As we showed earlier in the lessons, the best way to do this is to create a list that stores the names of the columns where replacement is needed. Then, use this list and iterate over the columns where the replacement is needed, performing the replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KplB5qWs_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "track      0\n",
      "artist     0\n",
      "genre      0\n",
      "city       0\n",
      "time       0\n",
      "day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loop through the columns replacing missing values with 'unknown'\n",
    "\n",
    "columns_to_replace = ['track','artist','genre']\n",
    "\n",
    "for col in columns_to_replace :\n",
    "    df [col].fillna ('unknow', inplace = True)\n",
    "    \n",
    "print (df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Now, check the result to ensure that there are no missing values in the dataset after the replacement. To do this, count the missing values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Tq4nYRX4_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "track      0\n",
      "artist     0\n",
      "genre      0\n",
      "city       0\n",
      "time       0\n",
      "day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values\n",
    "print (df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicates <a id='duplicates'></a>\n",
    "Find the number of explicit duplicates in the table. Once again, you should apply two methods in sequence to get the number of explicit duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "36eES_S0_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3826\n"
     ]
    }
   ],
   "source": [
    "# Count explicit duplicates\n",
    "print (df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Now, remove all the duplicates. To do this, call the method that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "exFHq6tt_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Remove explicit duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "print (df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Now, let's check if we successfully removed all the duplicates. Count the explicit duplicates once again to make sure all have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-8PuNWQ0_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check again for duplicates\n",
    "\n",
    "print (df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Now, we want to get rid of implicit duplicates in the `genre` column. For example, the name of a genre may be written in different ways. Such errors can also affect the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSjWwsOh_Zct"
   },
   "source": [
    "To do this, first let's display a list of unique genre names, sorted alphabetically. To do so:\n",
    "* Extract the `genre` column from the DataFrame.\n",
    "* Call the method that will return all the unique values in the extracted column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JIUcqzZN_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic' nan\n",
      " 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 'türkçe'\n",
      " 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n",
      " 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'variété'\n",
      " 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n",
      " 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n",
      " 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n",
      " 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n",
      " 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n",
      " 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n",
      " 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 'sängerportrait'\n",
      " 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n",
      " 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n",
      " 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n",
      " 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' 'ïîï' 'mood' 'surf'\n",
      " 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n",
      " 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n",
      " 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n",
      " 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n",
      " 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n",
      " 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n",
      " 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n",
      " 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n",
      " 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n",
      " 'handsup' 'punjabi' 'synthpop' 'rave' 'französisch' 'quebecois' 'speech'\n",
      " 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n",
      " 'jungle' 'indipop' 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n",
      " 'forró' 'dirty' 'regional']\n",
      "\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "# Inspect the unique genre names\n",
    "print (df['genre'].unique())\n",
    "print ()\n",
    "print (df['genre'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Search the list to find implicit duplicates of the genre `hiphop`. These may be incorrectly written names or alternative names for the same genre.\n",
    "\n",
    "You will see the following implicit duplicates:\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "To get rid of them, create a function called `replace_wrong_genres()` with two parameters:\n",
    "* `wrong_genres=`: this is a list containing all the values that need to be replaced.\n",
    "* `correct_genre=`: this is a string that will be used as the replacement.\n",
    "\n",
    "As a result, the function should correct the names in the `'genre'` column of the `df` table, meaning it should replace each value in the `wrong_genres` list with the value in `correct_genre`.\n",
    "\n",
    "Within the function body, use a `for` loop to iterate over the list of incorrect genres, extract the `'genre'` column, and apply the `replace` method to make the corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ErNDkmns_Zct"
   },
   "outputs": [],
   "source": [
    "# Function to replace implicit duplicates\n",
    "\n",
    "def replace_wrong_genres (df,column,wrong_genres,correct_genre):\n",
    "    for wrong_genre in wrong_genres :\n",
    "        df[column] = df[column].replace (wrong_genre, correct_genre)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Now, call `replace_wrong_genres()` and pass it such arguments that will remove the implicit duplicates (`hip`, `hop`, and `hip-hop`) and replace them with `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YN5i2hpmSo09"
   },
   "outputs": [],
   "source": [
    "# Remove implicit duplicates\n",
    "duplicates = ['hip','hop','hip-hop']\n",
    "name = 'hiphop'\n",
    "df = replace_wrong_genres (df,'genre', duplicates, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Make sure that the duplicate names have been removed. Display the list of unique values in the `'genre'` column once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wvixALnFG15m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic' nan\n",
      " 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 'türkçe'\n",
      " 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n",
      " 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'variété'\n",
      " 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n",
      " 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n",
      " 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n",
      " 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n",
      " 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n",
      " 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n",
      " 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 'sängerportrait'\n",
      " 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n",
      " 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n",
      " 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n",
      " 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' 'ïîï' 'mood' 'surf'\n",
      " 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n",
      " 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n",
      " 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n",
      " 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n",
      " 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n",
      " 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n",
      " 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n",
      " 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n",
      " 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n",
      " 'handsup' 'punjabi' 'synthpop' 'rave' 'französisch' 'quebecois' 'speech'\n",
      " 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n",
      " 'jungle' 'indipop' 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n",
      " 'forró' 'dirty' 'regional']\n",
      "\n",
      "268\n"
     ]
    }
   ],
   "source": [
    "# Checking for implicit duplicates\n",
    "\n",
    "print (df['genre'].unique())\n",
    "print ()\n",
    "print (df['genre'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Your observations <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "`Briefly describe what you noticed when analyzing duplicates, how you addressed their removal, and what results you obtained.`  \n",
    "A/ It is complex to determine which values are duplicated when there is a large amount of data in a single column. For example, in the case of \"hiphop\", if there are 1000 entries in the same column and 230 are duplicates, how can we easily identify which ones are or which they are? The removal method using functions is very useful because, with little code and less complexity in the description, it allows us to simplify the amount of data for analysis. However, I am not very satisfied with the result, as I would like to have a clearer comparison between the original table with duplicated data and the new one with the duplicates removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Stage 3. Hypothesis Testing <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hypothesis: compare user behavior in the two cities <a id='activity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "The hypothesis states that there are differences in the way users in Springfield and Shelbyville consume music. To test this, we will use data from three days of the week: Monday, Wednesday, and Friday.\n",
    "\n",
    "* Group users by city.\n",
    "* Compare the number of songs each group played on Monday, Wednesday, and Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw_YMmT_Zcu"
   },
   "source": [
    "Perform each calculation separately.\n",
    "\n",
    "The first step is to evaluate user activity in each city. Remember the divide-apply-combine stages we discussed earlier in the lesson. Your goal now is to group the data by city, apply the appropriate method to count during the apply stage, and then find the number of songs played in each group by specifying the column to get the count.\n",
    "\n",
    "Below is an example of what the final result should look like:\n",
    "`df.groupby(by='....')['column'].method()`\n",
    "\n",
    "Perform each calculation separately.\n",
    "\n",
    "To evaluate the activity of users in each city, group the data by city and find the number of songs played in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Qx-3NewAnK"
   },
   "source": [
    "`Comment your observations here`\n",
    "\n",
    "R/ It is a very good methodology to apply the 3 steps to segment and categorize the data in order to reach a clearer conclusion. It can be observed that in Springfield, there is a higher number of song plays across the three days compared to Shelbyville, surpassing it by double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0_Qs96oh_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "Shelbyville    18512\n",
      "Springfield    42741\n",
      "Name: day, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the songs played in each city\n",
    "\n",
    "print(df.groupby(by='city')['day'].count())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Now let's group the data by day of the week and find the number of songs played on Monday, Wednesday, and Friday. Use the same method as before, but now we need a different grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "uZMKjiJz_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day\n",
      "Friday       21840\n",
      "Monday       21354\n",
      "Wednesday    18059\n",
      "Name: city, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of songs played on each of the three days\n",
    "print(df.groupby(by='day')['city'].count())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "# Comment your observations here\n",
    "R/ The day with the highest number of plays is Friday, although Tuesday is not far behind, which indicates that weekends (at the start and end of the workday) show the highest increase in plays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "Now you know how to count entries by grouping them by city or day. Now, you need to write a function that can count entries based on both criteria simultaneously.\n",
    "\n",
    "Create the function `number_tracks()` to calculate the number of songs played on a given day **and** city. The function should accept two parameters:\n",
    "\n",
    "- `day`: a day of the week to filter by. For example, `'Monday'`.\n",
    "- `city`: a city to filter by. For example, `'Springfield'`.\n",
    "\n",
    "Inside the function, you will apply consecutive filtering with logical indexing.\n",
    "\n",
    "First, filter the data by day and then filter the resulting table by city.\n",
    "\n",
    "After filtering the data by two criteria, count the number of values in the 'user_id' column in the resulting table. This count represents the number of entries you're looking for. Save the result in a new variable and return it from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Nz3GdQB1_Zcu"
   },
   "outputs": [],
   "source": [
    "# Declare the function number_tracks() with two parameters: day= and city=.\n",
    "# Store the rows of the DataFrame where the value in the 'day' column equals the parameter day=\n",
    "# Filter the rows where the value in the 'city' column equals the parameter city=\n",
    "# Extract the 'user_id' column from the filtered table and apply the count() method\n",
    "# Return the number of values in the 'user_id' column\n",
    "\n",
    "def number_tracks (day,city):\n",
    "    df_filtered = df[df['day']==day]\n",
    "    df_filtered = df_filtered[df_filtered['city']==city]\n",
    "    df_filtered = df_filtered['user_id'].count()\n",
    "    return df_filtered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Call `number_tracks()` six times, changing the parameter values to retrieve data from both cities for each of the three days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rJcRATNQ_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15740\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Springfield on Monday\n",
    "\n",
    "df_filtered = number_tracks ('Monday','Springfield') \n",
    "\n",
    "print(df_filtered) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hq_ncZ5T_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5895\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Shelbyville on Monday\n",
    "df_filtered = number_tracks ('Monday','Shelbyville') \n",
    "\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_NTy2VPU_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11056\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Springfield on Wednesday\n",
    "df_filtered = number_tracks ('Wednesday','Springfield') \n",
    "\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "j2y3TAwo_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Shelbyville on Wednesday\n",
    "df_filtered = number_tracks ('Wednesday','Shelbyville') \n",
    "\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vYDw5u_K_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15945\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Springfield on Friday\n",
    "df_filtered = number_tracks ('Friday','Springfield') \n",
    "\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8_yzFtW3_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5895\n"
     ]
    }
   ],
   "source": [
    "# The number of songs played in Shelbyville on Friday\n",
    "df_filtered = number_tracks ('Friday','Shelbyville') \n",
    "\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "## **Conclusions**\n",
    "\n",
    "Comment on whether the hypothesis is correct or should be rejected. Explain your reasoning.\n",
    "\n",
    "**Hypothesis**: User activity differs depending on the day of the week and the city.\n",
    "\n",
    "**Response**: Yes, the hypothesis is correct according to the study, which indicates that Springfield is the city with the highest number of plays, with considerable increases on Fridays and Mondays. Possible reasons for this trend might include leisure activities in nightclubs, bars, restaurants, and other venues on Fridays, as well as workplace or radio station usage on Mondays to liven up the start of the workweek. However, more information would be required to validate these hypotheses further. Additionally, factors such as population density and city size should be considered to make the study more objective and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Final Conclusions <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "**Summarize your conclusions about the hypothesis.**\n",
    "\n",
    "**Response**: The hypothesis is correct. To complement the study, more information is needed, but with the data provided, this is a good starting point for identifying the day and city with the highest activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azLHu64yOIp7"
   },
   "source": [
    "### Note\n",
    "\n",
    "In real research projects, statistical hypothesis testing is more precise and quantitative. Also, keep in mind that conclusions about an entire city cannot always be drawn from data from a single source.\n",
    "\n",
    "You will learn more about hypothesis testing in the data statistical analysis sprint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju4AHDSgV1FE"
   },
   "source": [
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
