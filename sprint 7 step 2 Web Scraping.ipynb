{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries:\n",
    "import pandas as pd # To organize the information into a table.\n",
    "import requests # To retrieve the content of a web page.\n",
    "from bs4 import BeautifulSoup # To analyze that content and find the desired information.\n",
    "\n",
    "# URL of the website\n",
    "url = 'https://practicum-content.s3.us-west-1.amazonaws.com/data-analyst-eng/moved_chicago_weather_2017.html'\n",
    "\n",
    "# Retrieve the content of the web page\n",
    "req = requests.get(url)\n",
    "\n",
    "# Analyze the content of the page\n",
    "soup = BeautifulSoup(req.text, 'lxml') # Retrieves the web page content as a string, 'lxml' is the name of a parser that BeautifulSoup uses to read and understand the HTML code.\n",
    "\n",
    "# Find the specific table with the id 'weather_records'\n",
    "table = soup.find('table', attrs={\"id\": \"weather_records\"})\n",
    "\n",
    "# Get the table headers\n",
    "\n",
    "# Create an empty list to store the headers described by 'th' (table head).\n",
    "heading_table=[] \n",
    "\n",
    "# Loop to search the table for titles and append them to the table as text.\n",
    "for head in table.find_all('th'):\n",
    "    heading_table.append(head.text)\n",
    "\n",
    "# Get the table content\n",
    "\n",
    "# Create an empty list to store the rest of the content described by 'tr' (table row).\n",
    "content=[]\n",
    "\n",
    "# Loop to search the table for row content and append it to the table as text.\n",
    "for row in table.find_all('tr'):\n",
    "    if not row.find_all('th'):\n",
    "        content.append([element.text for element in row.find_all('td')]) # td (table cell) content in cells.\n",
    "\n",
    "# We create an empty list. Then, we search for all rows in the table (marked with <tr>). If a row does not have headers (to avoid duplicating the headers), we take all the elements of the row (marked with <td>) and add their text to our content list.\n",
    "\n",
    "\n",
    "# Create a DataFrame with the information\n",
    "weather_records = pd.DataFrame(content, columns=heading_table)\n",
    "# The table has the headers stored in heading_table and the content stored in content.\n",
    "\n",
    "# Print the complete DataFrame\n",
    "print(weather_records)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
